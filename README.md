# ğŸ¦Ÿ API de Monitoramento e InteligÃªncia de Dengue

> **Data Lake e Dashboard de visualizaÃ§Ã£o de dados epidemiolÃ³gicos em tempo real.**

Este projeto Ã© uma API Backend robusta desenvolvida em **Python (FastAPI)** que coleta, processa e armazena dados epidemiolÃ³gicos da Dengue no Brasil. Ele atua como uma camada de inteligÃªncia (Data Lake), consumindo dados da API oficial do **InfoDengue (Fiocruz/FGV)** e disponibilizando-os atravÃ©s de uma API performÃ¡tica e um Dashboard interativo de mapas de calor.

---

## ğŸš€ Funcionalidades Principais

* **ETL Automatizado:** SincronizaÃ§Ã£o automÃ¡tica de dados epidemiolÃ³gicos (Casos, NÃ­vel de Alerta, Rt) para todos os **5.570 municÃ­pios brasileiros**.
* **Alta Performance:** Utiliza **processamento assÃ­ncrono** e inserÃ§Ã£o em lotes (*Batch Upsert*) para lidar com milhÃµes de registros histÃ³ricos sem travar o banco.
* **Banco de Dados Temporal:** HistÃ³rico completo semanal (Semana EpidemiolÃ³gica) persistido em PostgreSQL.
* **Dashboard Interativo:**
    * **NÃ­vel Nacional:** Mapa coroplÃ©tico dos estados brasileiros.
    * **NÃ­vel Municipal (Drill-down):** VisualizaÃ§Ã£o granular por cidade (Demo implementada para **Pernambuco**).
* **API RESTful:** Endpoints flexÃ­veis para consulta e filtragem de dados.

---

## ğŸ› ï¸ Stack TecnolÃ³gica

* **Linguagem:** Python 3.10+
* **Framework Web:** FastAPI (ASGI)
* **Banco de Dados:** PostgreSQL 15 (via Docker)
* **ORM:** SQLAlchemy (Asyncio) + Alembic (MigraÃ§Ãµes)
* **Cliente HTTP:** HTTPX (RequisiÃ§Ãµes assÃ­ncronas paralelas)
* **Agendamento:** APScheduler (Cron jobs)
* **VisualizaÃ§Ã£o:** Folium (Leaflet.js) + Pandas
* **Gerenciamento de DependÃªncias:** Poetry

---

## âš™ï¸ PrÃ©-requisitos

* Docker e Docker Compose
* Python 3.10 ou superior
* Poetry (Gerenciador de pacotes)

---

## ğŸ“¦ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone [https://github.com/seu-usuario/dengue-api.git](https://github.com/seu-usuario/dengue-api.git)
cd dengue-api
```

### 2. Configure as VariÃ¡veis de Ambiente

Copie o arquivo de exemplo e, se necessÃ¡rio, ajuste as credenciais do banco no arquivo `.env` gerado.

```bash
cp .env.example .env
```

### 3. Inicie o Banco de Dados

Suba o container do PostgreSQL via Docker.

```bash
docker-compose up -d
```

### 4. Instale as DependÃªncias

```bash
poetry install
```

### 5. Execute as MigraÃ§Ãµes do Banco

Crie as tabelas no banco de dados.

```bash
poetry run alembic upgrade head
```

### ğŸŒ± Carga de Dados (Seed & Backfill)

Antes de usar o dashboard, Ã© necessÃ¡rio popular o banco de dados. Execute os scripts na ordem abaixo:

#### Passo 1: Popular MunicÃ­pios (TerritÃ³rios)

Baixa a lista oficial do IBGE e popula a tabela `territories`.

```bash
poetry run python src/app/scripts/seed_territories.py
```

#### Passo 2: Carga HistÃ³rica (Backfill)

Baixa os dados de dengue semanais dos Ãºltimos anos (2023 atÃ© o presente) para todas as cidades.

âš ï¸ **AtenÃ§Ã£o:** Este processo dispara milhares de requisiÃ§Ãµes HTTP e pode levar alguns minutos.

```bash
poetry run python src/app/scripts/backfill_infodengue.py
```

---

## â–¶ï¸ Como Rodar

Inicie o servidor de desenvolvimento:

```bash
poetry run uvicorn src.app.main:app --reload
```

O servidor estarÃ¡ rodando em `http://127.0.0.1:8000`.

---

## ğŸ“Š Acessando o Projeto

### ğŸ—ºï¸ Dashboard Visual

Acesse o mapa interativo para visualizar a evoluÃ§Ã£o da doenÃ§a: ğŸ‘‰ `http://127.0.0.1:8000/api/v1/map/dashboard`

**Como usar:**

*   Selecione a **Semana EpidemiolÃ³gica** desejada no canto superior direito.
*   Alterne entre a visÃ£o **Brasil (Estados)** e **Pernambuco (Cidades)** usando os botÃµes no topo.

### ğŸ“‘ DocumentaÃ§Ã£o da API (Swagger UI)

Explore e teste os endpoints disponÃ­veis (JSON): ğŸ‘‰ `http://127.0.0.1:8000/docs`

---

## ğŸ“‚ Estrutura do Projeto

```plaintext
dengue-api/
â”œâ”€â”€ migrations/          # Scripts de migraÃ§Ã£o do banco (Alembic)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/         # Endpoints (Routes) da API
â”‚   â”‚   â”œâ”€â”€ core/        # ConfiguraÃ§Ãµes e Scheduler
â”‚   â”‚   â”œâ”€â”€ db/          # ConfiguraÃ§Ã£o do Banco de Dados
â”‚   â”‚   â”œâ”€â”€ models/      # Modelos ORM (SQLAlchemy)
â”‚   â”‚   â”œâ”€â”€ schemas/     # Schemas Pydantic (ValidaÃ§Ã£o)
â”‚   â”‚   â”œâ”€â”€ scripts/     # Scripts de carga de dados (Seed/Backfill)
â”‚   â”‚   â””â”€â”€ services/    # LÃ³gica de negÃ³cio (InfoDengue Sync, Map Generation)
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ geo/         # Arquivos GeoJSON (Mapas)
â”œâ”€â”€ docker-compose.yml   # Infraestrutura
â””â”€â”€ pyproject.toml       # DependÃªncias
```

---

## ğŸ”® Contexto de IoT (Internet das Coisas)

Este projeto serve como a camada de **Processamento e Data Lake** em uma arquitetura de IoT para **Cidades Inteligentes**. A infraestrutura foi projetada para suportar expansÃµes futuras, tais as:

*   **IngestÃ£o de Sensores:** Receber dados de estaÃ§Ãµes meteorolÃ³gicas (temperatura/umidade) via API.
*   **CorrelaÃ§Ã£o de Dados:** Cruzar dados climÃ¡ticos locais com o risco epidemiolÃ³gico.
*   **Dispositivos de Borda:** Servir como backend para painÃ©is de alerta fÃ­sicos baseados em ESP32/Arduino.
